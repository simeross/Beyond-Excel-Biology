---
title: Will dishwashers replace you?
date: 2026-02-04
tags:
  - AI
  - efficiency
draft: false
---
AI tools are highly versatile but prone to certain types of mistakes. In this post, I ponder whether this is always a problem and use dishwashers as an analogy to consider when to use generative AI.
<!--more-->
## Move fast and break things
When the LLM hype began, I was mostly sceptical about how useful these tools would be in my daily work and by extension, in other jobs. I also did not buy the 'just wait for the next model' optimism that was and remains a large part of the general discourse around generative AI (GenAI). Concerns regarding the copyright and bias of training data and the immense energy demand of training and running GenAI models rightfully receive a lot of attention. These are problems that likely will continue to be urgent for years to come. The 'move fast and break things' mentality of the current tech economy has traded short-term financial and technological gains for seemingly unsolvable ethical dilemmas across industries. GenAI is only one symptom of this.

Disregarding the ethics, as we tend to do, my scepticism regarding the usefulness and potential for improvement in GenAI largely stemmed from the core of the technology. In my mental model, GenAI should never be trusted fully, because its output is not the result of understanding, but prediction of likely sequences. This flaw was inherent to the technology and could only be hidden more convincingly, but never removed. For an in-depth discussion of these points, I recommend two entertaining sibling blog posts: [A non-anthropomorphized view of LLMs](https://addxorrol.blogspot.com/2025/07/a-non-anthropomorphized-view-of-llms.html) by Thomas Dullien (Halvar Flake) and [Why we should anthropomorphize LLMs](https://www.seangoedecke.com/anthropomorphizing-llms/), a response by Sean Goedecke. Believing that a technology is not useful because of a propensity towards errors and a lack of reproducibility and reliability was na√Øve. It was a point of view informed by scientific idealism, a programming mindset and an unwillingness to anthropomorphize GenAI to any extent. An experiment that produces unreliable results or code that crashes out in 5 % of cases on the same machine are useless. But making errors is just human.
## Unlearning reproducibility
So, accepting that GenAI tools are sometimes all-knowing and never-tired assistants and sometimes frustratingly flawed and patiently but insistently wrong conspiracy theorists, I started using them differently. First mostly for my own entertainment, trying to get it to derail in funny ways or discussing absurd hypotheticals, but more and more for tasks like coding and planning. As a traditionally trained molecular biologist and self-trained bioinformatician, I have spotty domain knowledge of computer sciences and a strong background in the scientific method. I taught myself programmatic solutions to replace manual and proprietary data organization and visualization. This process was partially driven by a need to handle larger data sets, partially scientific rigor, and partially a fascination with the beauty of building working, reproducible little machines that reliably and quickly achieve a goal that would take me a long time to do manually. Of course building the machine might take longer the first couple of times, but that's a different story.

This academic ideal of programming as the creation of elegant bespoke machines or less elegant, functional tractors, that I know every part of intimately, is a luxury of my environment. Of being the sole producer and often sole user of my code. Real software engineers are actually engineers. They are thrown into code they didn't write and need to fix issues they didn't create in ways that work, regardless of elegance or reproducibility (although these are still ideals in the industry). In order to apply GenAI effectively, I needed to unlearn treating reproducibility as an inherent feature of automating tasks.

## Why we should anthropomorphise grad students
In the software world, GenAI tools are often compared to junior engineers. The academic equivalent would be a fresh grad/master student in the lab. You trust them to be capable of handling simple tasks independently, but they require supervision, guidance and corrections to be productive and safe. No matter how smart or capable they are, it is the responsibility of the senior engineer or supervisor to make sure that the work is done correctly before being integrated into the product or a scientific publication. Any task you give to such a person should generally be designed by the senior or the supervisor to be suitable for any junior, regardless of capability. Like many others, I find this comparison problematic, although it provides useful hints for the use of GenAI. It belittles junior engineers or researchers and reveals a deep misunderstanding of this dynamic. Although especially junior engineers and often grad students may feel and be treated like exchangeable and disposable resources for menial labour, the ideal is for them to learn and progress into senior roles themselves. Their performance of tasks is as much a highly individual teaching tool as it is the generation of potential value for the institution. The tasks and feedback should ideally be designed with this in mind and the juniors should be treated like future seniors. 

I believe that the correct amount of anthropomorphising for GenAI accepts that they are imperfect, make mistakes frequently and work best when treated with care and a gentle touch. But comparing them to junior engineers or researchers indicates to me that we treat some of our colleagues like machines more than it anthropomorphises GenAI. Instead, generative models should be viewed like dishwashers.
## Dishwasher-safe tasks
When I load the dishwasher, I do expect the majority of items to come out clean. I never know which ones won't and sometimes I spend ten minutes scrubbing a glass or spoon that has some gunk baked into its essence after the wash. Some things I may gamble on, some wooden boards from Ikea will go in, even though I know they will be warped or come apart at some point. But I have both rules of thumb and specific labels telling me what is dishwasher-safe and what isn't. 

When using GenAI these days, I can generally expect things to come out a certain way, but there is no guarantee. Sometimes I will use more manual labour fixing the mistakes than I would have spent solving a problem myself. There are general institutional rules on what can and can't be handled by the dishwasher (GDPR, proprietary information, ...). When I send the prompt, just like when I start the dishwasher, I have the short satisfaction of feeling the task is done and the hope that everything will come out clean. But the real work of sorting the dishes back into place and maybe scrubbing a little remains. And opening the dishwasher always has that weird smell that makes me question how clean the dishes actually are.